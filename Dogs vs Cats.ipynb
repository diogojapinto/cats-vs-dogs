{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dogs vs Cats - features\n",
    "\n",
    "[Kaggle](https://www.kaggle.com/c/dogs-vs-cats)\n",
    "\n",
    "1 = dog\n",
    "\n",
    "0 = cat\n",
    "\n",
    "Notes for report:\n",
    "    analyse how the variability of nr_features affects\n",
    "    try different detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "from os import listdir\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NR_SAMPLES = 100\n",
    "NR_WORDS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_folder = 'data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs_paths = [train_folder + filepath for filepath in listdir(train_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select a subset\n",
    "# imgs_paths = imgs_paths[:NR_SAMPLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "def load_images(imgs_paths, gray=False):\n",
    "    for path in imgs_paths:\n",
    "        img = cv2.imread(path)\n",
    "        \n",
    "        if gray:\n",
    "            yield cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            yield cv2.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = [1 if \"dog\" in path else 0 for path in imgs_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr dogs: 12500\n"
     ]
    }
   ],
   "source": [
    "print('Nr dogs:', labels.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr cats: 12500\n"
     ]
    }
   ],
   "source": [
    "print('Nr cats:', labels.count(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features detectors, descriptors and matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SIFT features detector and extractor\n",
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SURF features detector and extractor\n",
    "surf = cv2.xfeatures2d.SURF_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FAST features detector\n",
    "fast = cv2.FastFeatureDetector_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BRISK descriptors extractor\n",
    "br = cv2.BRISK_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FLANN matcher\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_bow(imgs, detector, matcher, extractor=None):\n",
    "    if extractor == None:\n",
    "        extractor = detector\n",
    "    \n",
    "    bow_trainer = cv2.BOWKMeansTrainer(NR_WORDS, \n",
    "                                       attempts=1, \n",
    "                                       flags=cv2.KMEANS_PP_CENTERS)\n",
    "    \n",
    "    bow_extractor = cv2.BOWImgDescriptorExtractor(extractor, matcher)\n",
    "    \n",
    "    for img in load_images(imgs, gray=True):\n",
    "        \n",
    "        kp = detector.detect(img)\n",
    "        kp, des = extractor.compute(img, kp)\n",
    "        \n",
    "        bow_trainer.add(des)\n",
    "        \n",
    "    vocabulary = bow_trainer.cluster()\n",
    "    \n",
    "    bow_extractor.setVocabulary(vocabulary)\n",
    "    \n",
    "    return bow_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = sift\n",
    "extractor = sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e635252776f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msift_bow_extractor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflann\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextractor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextractor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-6bbdca36ebda>\u001b[0m in \u001b[0;36mtrain_bow\u001b[1;34m(imgs, detector, matcher, extractor)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mkp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mkp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mbow_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sift_bow_extractor = train_bow(imgs_paths, detector, flann, extractor=extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = np.empty((0, NR_WORDS))\n",
    "imgs = load_images(imgs_paths, gray=True)\n",
    "\n",
    "for img in imgs:\n",
    "    kp = detector.detect(img)\n",
    "    \n",
    "    img_features = sift_bow_extractor.compute(img, kp)\n",
    "    \n",
    "    features = np.concatenate((features, img_features), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)\n",
    "\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names = ['dog', 'cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.base import clone as skl_clone\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def k_fold_model_select(features, labels, raw_classifiers, n_folds=10, weigh_samples_fn=None): \n",
    "    # weigh_samples_fn is explained below\n",
    "    # assumes that the raw_classifier output is in probability\n",
    "    \n",
    "    # split into training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                        labels,\n",
    "                                                        test_size=0.3,\n",
    "                                                        stratify=labels,\n",
    "                                                        random_state=0)\n",
    "    \n",
    "    \n",
    "    # use stratified k-fold cross validation to select the model\n",
    "    skf = StratifiedKFold(y_train, n_folds=n_folds)\n",
    "\n",
    "    best_classifier = None\n",
    "    best_score = float('-inf')\n",
    "\n",
    "    for train_index, validation_index in skf:\n",
    "        for raw_classifier in raw_classifiers:\n",
    "            classifier = skl_clone(raw_classifier)\n",
    "            classifier = classifier.fit(X_train[train_index], y_train[train_index])\n",
    "\n",
    "            if weigh_samples_fn != None:\n",
    "                y_pred = classifier.predict(X_train[validation_index])\n",
    "                sample_weight = weigh_samples_fn(y_train[validation_index], y_pred)\n",
    "            else:\n",
    "                sample_weight = None\n",
    "\n",
    "            score = accuracy_score(classifier.predict(X_train[validation_index]), y_train[validation_index],\n",
    "                                     sample_weight=sample_weight)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_classifier = classifier\n",
    "                best_score = score\n",
    "    \n",
    "    # compute the confusion matrix\n",
    "    y_pred = best_classifier.predict(X_test)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # now compute the score for the test data of the best found classifier\n",
    "    if weigh_samples_fn != None:\n",
    "        sample_weight = weigh_samples_fn(y_test, y_pred)\n",
    "    else:\n",
    "        sample_weight = None\n",
    "    test_score = accuracy_score(best_classifier.predict(X_test), y_test, sample_weight=sample_weight)\n",
    "    \n",
    "    # obtain the classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=['cat', 'dog'], sample_weight=sample_weight)\n",
    "    \n",
    "    # obtain ROC curve\n",
    "    y_test_bin = label_binarize(y_test, classes=[0, 1])\n",
    "    y_prob = best_classifier.predict_proba(X_test)\n",
    "    \n",
    "    #fpr, tpr, _ = roc_curve(y_test_bin[:, 1], y_prob[:, 1])\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin, y_prob[:, 1])\n",
    "    roc_info = (best_classifier.__class__.__name__, (fpr, tpr))\n",
    "    \n",
    "    return (test_score, report, conf_mat, roc_info, best_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(weights='distance', algorithm='auto')\n",
    "knn_score, knn_rep, knn_cm, knn_roc, knn_clf = k_fold_model_select(features, labels, [knn])\n",
    "\n",
    "print(\"Nearest Neighbors\")\n",
    "print(\"Score:\", knn_score)\n",
    "print(\"Confusion matrix:\", knn_cm, sep='\\n')\n",
    "print(\"Classification report:\", knn_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb_score, nb_rep, nb_cm, nb_roc, nb_clf = k_fold_model_select(features, labels, [nb])\n",
    "\n",
    "print(\"Gaussian Naive Bayes\")\n",
    "print(\"Score:\", nb_score)\n",
    "print(\"Confusion matrix:\", nb_cm, sep='\\n')\n",
    "print(\"Classification report:\", nb_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=0, class_weight='balanced', probability=True)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('min/max scaler', MinMaxScaler(feature_range=(0.0, 1.0))),\n",
    "        ('svc linear', svc)])\n",
    "\n",
    "svc_score, svc_rep, svc_cm, svc_roc, svc_clf = \\\n",
    "    k_fold_model_select(features, labels, [pipeline])\n",
    "\n",
    "print(\"SVM\")\n",
    "print(\"Score:\", svc_score)\n",
    "print(\"Confusion matrix:\", svc_cm, sep='\\n')\n",
    "print(\"Classification report:\", svc_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(min_samples_split=15, random_state=0, min_samples_leaf=5, class_weight='balanced')\n",
    "\n",
    "ab = AdaBoostClassifier(base_estimator=dt, random_state=0)\n",
    "ab_score, ab_rep, ab_cm, ab_roc, ab_clf = k_fold_model_select( features, labels, [ab])\n",
    "\n",
    "print(\"AdaBoos\")\n",
    "print(\"Score:\", ab_score)\n",
    "print(\"Confusion matrix:\", ab_cm, sep='\\n')\n",
    "print(\"Classification report:\", ab_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "rf_score, rf_rep, rf_cm, rf_roc, rf_clf = k_fold_model_select(features, labels, [rf])\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"Score:\", rf_score)\n",
    "print(\"Confusion matrix:\", rf_cm, sep='\\n')\n",
    "print(\"Classification report:\", rf_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [knn_clf, nb_clf, svc_clf, ab_clf, rf_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_score, best_rep, best_cm, best_roc, best_clf = k_fold_model_select(features, labels, classifiers)\n",
    "\n",
    "print(\"Classifier:\", best_clf.__class__.__name__)\n",
    "print(\"Score:\", best_score)\n",
    "print(\"Confusion matrix:\", best_cm, sep='\\n')\n",
    "print(\"Classification report:\", best_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "\n",
    "pk.dump(best_clf, open('best_clf.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curves(roc_curves):\n",
    "    for name, (fpr, tpr) in roc_curves:\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC for {} (area = {:0.2f})'.format(name, roc_auc))\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(2.1, 1.05))\n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_curves = [knn_roc, nb_roc, svc_roc, ab_roc, rf_roc]\n",
    "\n",
    "plot_roc_curves(roc_curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_labels_csv(labels):\n",
    "    indexed_labels = np.concatenate((np.asmatrix(range(1, len(labels) + 1)).transpose(), np.asmatrix(labels)), axis=1)\n",
    "    \n",
    "    print(indexed_labels)\n",
    "    \n",
    "    np.savetxt('result.csv', \n",
    "               indexed_labels,\n",
    "               fmt='%d',\n",
    "               delimiter=',',\n",
    "               header='id,label',\n",
    "               comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_folder = 'data/test1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_imgs_paths = [test_folder + filepath for filepath in listdir(test_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_imgs_paths = test_imgs_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "test_imgs = load_images(test_imgs_paths, gray=True)\n",
    "\n",
    "for img in test_imgs:\n",
    "    \n",
    "    kp = detector.detect(img)\n",
    "    img_features = sift_bow_extractor.compute(img, kp)\n",
    "    \n",
    "    p = best_clf.predict(img_features)\n",
    "    \n",
    "    pred.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_labels_csv(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
