{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dogs vs Cats - features\n",
    "\n",
    "[Kaggle](https://www.kaggle.com/c/dogs-vs-cats)\n",
    "\n",
    "1 = dog\n",
    "\n",
    "0 = cat\n",
    "\n",
    "Notes for report:\n",
    "    analyse how the variability of nr_features affects\n",
    "    try different detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "from os import listdir\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NR_WORDS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "def load_images(imgs_paths, gray=False):\n",
    "    for path in imgs_paths:\n",
    "        img = cv2.imread(path)\n",
    "        \n",
    "        if gray:\n",
    "            yield cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            yield cv2.imread(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features detectors, descriptors and matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SIFT features detector and extractor\n",
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FLANN matcher\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_bow(detector, matcher, extractor=None):\n",
    "    if extractor == None:\n",
    "        extractor = detector\n",
    "    \n",
    "    bow_extractor = cv2.BOWImgDescriptorExtractor(extractor, matcher)\n",
    "    \n",
    "    vocabulary = pk.load(open('vocabulary.p', 'rb'))\n",
    "    \n",
    "    bow_extractor.setVocabulary(vocabulary)\n",
    "    \n",
    "    return bow_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = sift\n",
    "extractor = sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sift_bow_extractor = train_bow(detector, flann, extractor=extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_folder = 'data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_paths = [train_folder + filepath for filepath in listdir(train_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = np.empty((0, NR_WORDS))\n",
    "imgs = load_images(imgs_paths, gray=True)\n",
    "\n",
    "for img in imgs:\n",
    "    kp = detector.detect(img)\n",
    "    \n",
    "    img_features = sift_bow_extractor.compute(img, kp)\n",
    "    \n",
    "    features = np.concatenate((features, img_features), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [1 if \"dog\" in path else 0 for path in imgs_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names = ['dog', 'cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pk.dump((features, labels), open('features_labels_diogo.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.base import clone as skl_clone\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def k_fold_model_select(features, labels, raw_classifiers, n_folds=10, weigh_samples_fn=None): \n",
    "    # weigh_samples_fn is explained below\n",
    "    # assumes that the raw_classifier output is in probability\n",
    "    \n",
    "    # split into training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                        labels,\n",
    "                                                        test_size=0.3,\n",
    "                                                        stratify=labels,\n",
    "                                                        random_state=0)\n",
    "    \n",
    "    \n",
    "    # use stratified k-fold cross validation to select the model\n",
    "    skf = StratifiedKFold(y_train, n_folds=n_folds)\n",
    "\n",
    "    best_classifier = None\n",
    "    best_score = float('-inf')\n",
    "\n",
    "    for train_index, validation_index in skf:\n",
    "        for raw_classifier in raw_classifiers:\n",
    "            classifier = skl_clone(raw_classifier)\n",
    "            classifier = classifier.fit(X_train[train_index], y_train[train_index])\n",
    "\n",
    "            if weigh_samples_fn != None:\n",
    "                y_pred = classifier.predict(X_train[validation_index])\n",
    "                sample_weight = weigh_samples_fn(y_train[validation_index], y_pred)\n",
    "            else:\n",
    "                sample_weight = None\n",
    "\n",
    "            score = accuracy_score(classifier.predict(X_train[validation_index]), y_train[validation_index],\n",
    "                                     sample_weight=sample_weight)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_classifier = classifier\n",
    "                best_score = score\n",
    "    \n",
    "    # compute the confusion matrix\n",
    "    y_pred = best_classifier.predict(X_test)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # now compute the score for the test data of the best found classifier\n",
    "    if weigh_samples_fn != None:\n",
    "        sample_weight = weigh_samples_fn(y_test, y_pred)\n",
    "    else:\n",
    "        sample_weight = None\n",
    "    test_score = accuracy_score(best_classifier.predict(X_test), y_test, sample_weight=sample_weight)\n",
    "    \n",
    "    # obtain the classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=['cat', 'dog'], sample_weight=sample_weight)\n",
    "    \n",
    "    # obtain ROC curve\n",
    "    y_test_bin = label_binarize(y_test, classes=[0, 1])\n",
    "    y_prob = best_classifier.predict_proba(X_test)\n",
    "    \n",
    "    #fpr, tpr, _ = roc_curve(y_test_bin[:, 1], y_prob[:, 1])\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin, y_prob[:, 1])\n",
    "    roc_info = (best_classifier.__class__.__name__, (fpr, tpr))\n",
    "    \n",
    "    return (test_score, report, conf_mat, roc_info, best_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "Score: 0.604\n",
      "Confusion matrix:\n",
      "[[2062 1688]\n",
      " [1282 2468]]\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        cat       0.62      0.55      0.58      3750\n",
      "        dog       0.59      0.66      0.62      3750\n",
      "\n",
      "avg / total       0.61      0.60      0.60      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(weights='distance', algorithm='auto')\n",
    "knn_score, knn_rep, knn_cm, knn_roc, knn_clf = k_fold_model_select(features, labels, [knn])\n",
    "\n",
    "print(\"Nearest Neighbors\")\n",
    "print(\"Score:\", knn_score)\n",
    "print(\"Confusion matrix:\", knn_cm, sep='\\n')\n",
    "print(\"Classification report:\", knn_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes\n",
      "Score: 0.575066666667\n",
      "Confusion matrix:\n",
      "[[1914 1836]\n",
      " [1351 2399]]\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        cat       0.59      0.51      0.55      3750\n",
      "        dog       0.57      0.64      0.60      3750\n",
      "\n",
      "avg / total       0.58      0.58      0.57      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb_score, nb_rep, nb_cm, nb_roc, nb_clf = k_fold_model_select(features, labels, [nb])\n",
    "\n",
    "print(\"Gaussian Naive Bayes\")\n",
    "print(\"Score:\", nb_score)\n",
    "print(\"Confusion matrix:\", nb_cm, sep='\\n')\n",
    "print(\"Classification report:\", nb_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "svc = SVC(kernel='linear', random_state=0, probability=True, max_iter=100)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('min/max scaler', MinMaxScaler(feature_range=(0.0, 1.0))),\n",
    "        ('svc linear', svc)])\n",
    "\n",
    "svc_score, svc_rep, svc_cm, svc_roc, svc_clf = \\\n",
    "    k_fold_model_select(features, labels, [pipeline])\n",
    "\n",
    "print(\"SVM\")\n",
    "print(\"Score:\", svc_score)\n",
    "print(\"Confusion matrix:\", svc_cm, sep='\\n')\n",
    "print(\"Classification report:\", svc_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(min_samples_split=15, random_state=0, min_samples_leaf=5)\n",
    "\n",
    "ab = AdaBoostClassifier(base_estimator=dt, random_state=0)\n",
    "ab_score, ab_rep, ab_cm, ab_roc, ab_clf = k_fold_model_select( features, labels, [ab])\n",
    "\n",
    "print(\"AdaBoos\")\n",
    "print(\"Score:\", ab_score)\n",
    "print(\"Confusion matrix:\", ab_cm, sep='\\n')\n",
    "print(\"Classification report:\", ab_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Score: 0.6636\n",
      "Confusion matrix:\n",
      "[[2686 1064]\n",
      " [1459 2291]]\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        cat       0.65      0.72      0.68      3750\n",
      "        dog       0.68      0.61      0.64      3750\n",
      "\n",
      "avg / total       0.67      0.66      0.66      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "rf_score, rf_rep, rf_cm, rf_roc, rf_clf = k_fold_model_select(features, labels, [rf])\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"Score:\", rf_score)\n",
    "print(\"Confusion matrix:\", rf_cm, sep='\\n')\n",
    "print(\"Classification report:\", rf_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classifiers = [knn_clf, nb_clf, svc_clf, ab_clf, rf_clf]\n",
    "classifiers = [knn_clf, nb_clf, rf_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_score, best_rep, best_cm, best_roc, best_clf = k_fold_model_select(features, labels, classifiers)\n",
    "\n",
    "print(\"Classifier:\", best_clf.__class__.__name__)\n",
    "print(\"Score:\", best_score)\n",
    "print(\"Confusion matrix:\", best_cm, sep='\\n')\n",
    "print(\"Classification report:\", best_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "\n",
    "best_clf = rf_clf\n",
    "\n",
    "best_clf = best_clf.fit(features, labels)\n",
    "\n",
    "pk.dump(best_clf, open('best_clf.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_clf = pk.load(open('best_clf.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curves(roc_curves):\n",
    "    for name, (fpr, tpr) in roc_curves:\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC for {} (area = {:0.2f})'.format(name, roc_auc))\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(2.1, 1.05))\n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svc_roc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-07ab5c9b62cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroc_curves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mknn_roc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_roc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvc_roc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mab_roc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_roc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplot_roc_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_curves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'svc_roc' is not defined"
     ]
    }
   ],
   "source": [
    "roc_curves = [knn_roc, nb_roc, svc_roc, ab_roc, rf_roc]\n",
    "\n",
    "plot_roc_curves(roc_curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_labels_csv(labels):\n",
    "    indexed_labels = np.concatenate((np.asmatrix(range(1, len(labels) + 1)).transpose(), np.asmatrix(labels)), axis=1)\n",
    "    \n",
    "    np.savetxt('result.csv', \n",
    "               indexed_labels,\n",
    "               fmt='%d',\n",
    "               delimiter=',',\n",
    "               header='id,label',\n",
    "               comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_folder = 'data/test1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_imgs_paths = [test_folder + filepath for filepath in listdir(test_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary\n",
    "#test_imgs_paths = test_imgs_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c45e9829c51e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mkp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mimg_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift_bow_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "\n",
    "#test_imgs_paths = test_imgs_paths[6384:]\n",
    "\n",
    "test_imgs = load_images(test_imgs_paths, gray=True)\n",
    "\n",
    "for i, img in enumerate(test_imgs):\n",
    "    \n",
    "    if( i is not 6383 ):\n",
    "        print(i)\n",
    "        kp = detector.detect(img)\n",
    "        img_features = sift_bow_extractor.compute(img, kp)\n",
    "\n",
    "        p = best_clf.predict(img_features)\n",
    "\n",
    "        pred.append(p)\n",
    "    else:\n",
    "        pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_labels_csv(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499\n"
     ]
    }
   ],
   "source": [
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred2 = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred2.insert(6383, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred[6383] = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
